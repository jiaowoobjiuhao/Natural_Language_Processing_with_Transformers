{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ç¬¬6ç«  æ–‡æœ¬æ‘˜è¦","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-28T10:48:22.624372Z","iopub.execute_input":"2024-02-28T10:48:22.624716Z","iopub.status.idle":"2024-02-28T10:48:36.352521Z","shell.execute_reply.started":"2024-02-28T10:48:22.624688Z","shell.execute_reply":"2024-02-28T10:48:36.351450Z"}}},{"cell_type":"code","source":"pip install datasets","metadata":{"execution":{"iopub.status.busy":"2024-02-29T03:33:47.330130Z","iopub.execute_input":"2024-02-29T03:33:47.330396Z","iopub.status.idle":"2024-02-29T03:34:01.042133Z","shell.execute_reply.started":"2024-02-29T03:33:47.330371Z","shell.execute_reply":"2024-02-29T03:34:01.041014Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->datasets) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.20.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.13.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset \ndataset = load_dataset('ccdv/cnn_dailymail', '3.0.0')\nprint(f\"Features: {dataset['train'].column_names}\") ","metadata":{"execution":{"iopub.status.busy":"2024-02-29T03:34:25.582580Z","iopub.execute_input":"2024-02-29T03:34:25.583213Z","iopub.status.idle":"2024-02-29T03:37:26.128137Z","shell.execute_reply.started":"2024-02-29T03:34:25.583178Z","shell.execute_reply":"2024-02-29T03:37:26.127176Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/9.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d3e66c00665494b9adf2577771f888c"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset cnn_dailymail/3.0.0 to /root/.cache/huggingface/datasets/ccdv___cnn_dailymail/3.0.0/3.0.0/0107f7388b5c6fae455a5661bcd134fc22da53ea75852027040d8d1e997f101f...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4b6e7d5127d4eb3943ebdb8daf70b76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/159M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c166fa3f9b8419b96f3728ae85ded06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/376M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"449f7ed939a940c08d7ee17111d19aae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/572k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d9baf76391b4a338c25a5aa8b46cae0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/12.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43c828718e474130bd4180a8b22c10d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/661k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2006f94cf74e4febbb8baec5432c52a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bd53d0153cc40a08082bd7d4b57972b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset cnn_dailymail downloaded and prepared to /root/.cache/huggingface/datasets/ccdv___cnn_dailymail/3.0.0/3.0.0/0107f7388b5c6fae455a5661bcd134fc22da53ea75852027040d8d1e997f101f. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"207cd11d370c4770aca7efb072791ae6"}},"metadata":{}},{"name":"stdout","text":"Features: ['article', 'highlights', 'id']\n","output_type":"stream"}]},{"cell_type":"code","source":"sample = dataset[\"train\"][1] \nprint(f\"\"\" Article (excerpt of 500 characters, total length: {len(sample[\"article\"])}): \"\"\") \nprint(sample[\"article\"][:500]) \nprint(f'\\nSummary (length: {len(sample[\"highlights\"])}):')\nprint(sample[\"highlights\"])","metadata":{"execution":{"iopub.status.busy":"2024-02-29T03:37:56.412054Z","iopub.execute_input":"2024-02-29T03:37:56.412907Z","iopub.status.idle":"2024-02-29T03:37:56.422860Z","shell.execute_reply.started":"2024-02-29T03:37:56.412876Z","shell.execute_reply":"2024-02-29T03:37:56.421960Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":" Article (excerpt of 500 characters, total length: 3192): \n(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay. The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds. The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover. The 26-year-old Bolt has n\n\nSummary (length: 180):\nUsain Bolt wins third gold of world championship .\nAnchors Jamaica to 4x100m relay victory .\nEighth gold at the championships for Bolt .\nJamaica double up in women's 4x100m relay .\n","output_type":"stream"}]},{"cell_type":"code","source":"sample_text = dataset[\"train\"][1][\"article\"][:2000] \n# We'll collect the generated summaries of each model in a dictionary \nsummaries = {}","metadata":{"execution":{"iopub.status.busy":"2024-02-29T03:37:59.609952Z","iopub.execute_input":"2024-02-29T03:37:59.610346Z","iopub.status.idle":"2024-02-29T03:37:59.615175Z","shell.execute_reply.started":"2024-02-29T03:37:59.610317Z","shell.execute_reply":"2024-02-29T03:37:59.614236Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import nltk \nfrom nltk.tokenize import sent_tokenize\nnltk.download(\"punkt\") \nstring = \"The U.S. are a country. The U.N. is an organization.\" \nsent_tokenize(string)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T03:38:07.325912Z","iopub.execute_input":"2024-02-29T03:38:07.326288Z","iopub.status.idle":"2024-02-29T03:38:08.681668Z","shell.execute_reply.started":"2024-02-29T03:38:07.326258Z","shell.execute_reply":"2024-02-29T03:38:08.680795Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"['The U.S. are a country.', 'The U.N. is an organization.']"},"metadata":{}}]},{"cell_type":"code","source":"def three_sentence_summary(text): \n\treturn \"\\n\".join(sent_tokenize(text)[:3]) \nsummaries[\"baseline\"] = three_sentence_summary(sample_text)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T03:38:32.070952Z","iopub.execute_input":"2024-02-29T03:38:32.071922Z","iopub.status.idle":"2024-02-29T03:38:32.077329Z","shell.execute_reply.started":"2024-02-29T03:38:32.071888Z","shell.execute_reply":"2024-02-29T03:38:32.076479Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline, set_seed \nset_seed(42) \npipe = pipeline(\"text-generation\", model=\"gpt2-xl\") \ngpt2_query = sample_text + \"\\nTL;DR:\\n\" \npipe_out = pipe(gpt2_query, max_length=512, clean_up_tokenization_spaces=True)\n\nsummaries[\"gpt2\"] = \"\\n\".join( sent_tokenize(pipe_out[0][\"generated_text\"][len(gpt2_query) :]))\n","metadata":{"execution":{"iopub.status.busy":"2024-02-29T03:38:36.488110Z","iopub.execute_input":"2024-02-29T03:38:36.488481Z","iopub.status.idle":"2024-02-29T03:39:53.149231Z","shell.execute_reply.started":"2024-02-29T03:38:36.488450Z","shell.execute_reply":"2024-02-29T03:39:53.148370Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"2024-02-29 03:38:42.098837: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-29 03:38:42.098984: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-29 03:38:42.267194: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/689 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aefb2b35d71a400881ea410b5c5ca5fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/6.43G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c90a77231af841119a43a660477d7310"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7c917c8784e4a73be1ad93fa808c7c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2981da09bb794abaa2ae3c3f3d289116"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e75c5e6a04b54aadbd83e8c7e9a55c7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98679d026e754faabedcef5a95bab2ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"891f5696b6324de48a44c1748a483c63"}},"metadata":{}},{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"}]},{"cell_type":"code","source":"pipe = pipeline(\"summarization\", model=\"t5-large\") \npipe_out = pipe(sample_text) \nsummaries[\"t5\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))","metadata":{"execution":{"iopub.status.busy":"2024-02-29T03:40:19.951763Z","iopub.execute_input":"2024-02-29T03:40:19.952770Z","iopub.status.idle":"2024-02-29T03:41:00.394830Z","shell.execute_reply.started":"2024-02-29T03:40:19.952735Z","shell.execute_reply":"2024-02-29T03:41:00.394022Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0dbf5ce4189b4ec7b5c3734a8308f531"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e09e7389bd9414da4da95b2c46d695f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8d072a03410432dafc61f0f65170a75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01f8f765718745a585d756ed2d05fb34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fab4b01c63d24ab1886ffff6de5626f3"}},"metadata":{}}]},{"cell_type":"code","source":"pipe = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\") \npipe_out = pipe(sample_text) \nsummaries[\"bart\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))","metadata":{"execution":{"iopub.status.busy":"2024-02-29T03:42:13.118049Z","iopub.execute_input":"2024-02-29T03:42:13.118403Z","iopub.status.idle":"2024-02-29T03:42:32.973205Z","shell.execute_reply.started":"2024-02-29T03:42:13.118374Z","shell.execute_reply":"2024-02-29T03:42:32.972344Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63c12120bd6a43588f5372110a198230"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de0bf9de3fb246c795d9c7bbe301ce5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1b586185ad3465fb89e438efba6a1f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c76e01471b247ad917d45f8a872bb86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa6c7a3c808242cba1530d81d8f9e39d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2e56edc3d5945beb6e4803fd15609d6"}},"metadata":{}}]},{"cell_type":"code","source":"pipe = pipeline(\"summarization\", model=\"google/pegasus-cnn_dailymail\") \npipe_out = pipe(sample_text) \nsummaries[\"pegasus\"] = pipe_out[0][\"summary_text\"].replace(\" .<n>\", \".\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-02-29T03:43:31.976405Z","iopub.execute_input":"2024-02-29T03:43:31.976765Z","iopub.status.idle":"2024-02-29T03:44:13.011200Z","shell.execute_reply.started":"2024-02-29T03:43:31.976736Z","shell.execute_reply":"2024-02-29T03:44:13.010375Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.12k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"941e92db7cd34b67aece10762754ce01"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a43f02a3b1914b3ba08eb50771ad5d10"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nSome weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/280 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89229e2e309d4aa3b039637279afd27d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/88.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"735dc383dbc64551a52029ab7e539634"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5617750063384676ad5e5691e8ba0909"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e877971c3a0244f3a70657d39a9a5dcd"}},"metadata":{}}]},{"cell_type":"code","source":"print(\"GROUND TRUTH\") \nprint(dataset[\"train\"][1][\"highlights\"]) \nprint(\"\") \nfor model_name in summaries: \n\tprint(model_name.upper()) \n\tprint(summaries[model_name]) \n\tprint(\"\")","metadata":{"execution":{"iopub.status.busy":"2024-02-29T03:45:57.307097Z","iopub.execute_input":"2024-02-29T03:45:57.308021Z","iopub.status.idle":"2024-02-29T03:45:57.315505Z","shell.execute_reply.started":"2024-02-29T03:45:57.307977Z","shell.execute_reply":"2024-02-29T03:45:57.314407Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"GROUND TRUTH\nUsain Bolt wins third gold of world championship .\nAnchors Jamaica to 4x100m relay victory .\nEighth gold at the championships for Bolt .\nJamaica double up in women's 4x100m relay .\n\nBASELINE\n(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay.\nThe fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds.\nThe U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover.\n\nGPT2\nBolt finished in style by winning the final sprint event in Moscow.\nThere is still a few sprint events to go before Friday's final but so far this final gold should stand as a world record.\n\nT5\nusain bolt wins his third gold medal of the world championships in the men's 4x100m relay .\nthe 26-year-old anchored Jamaica to victory in the event in the Russian capital .\nhe has now collected eight gold medals at the championships, equaling the record .\n\nBART\nUsain Bolt wins his third gold of the world championships in Moscow.\nBolt anchors Jamaica to victory in the men's 4x100m relay.\nThe 26-year-old has now won eight gold medals at world championships.\nJamaica's women also win gold in the relay, beating France in the process.\n\nPEGASUS\nUsain Bolt wins third gold of world championships.\nAnchors Jamaica to victory in men's 4x100m relay.\nEighth gold at the championships for Bolt.\nJamaica also win women's 4x100m relay .\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install sacrebleu\nfrom datasets import load_metric \nbleu_metric = load_metric(\"sacrebleu\")\nimport pandas as pd \nimport numpy as np \nbleu_metric.add( prediction=\"the the the the the the\", reference=[\"the cat is on the mat\"]) \nresults = bleu_metric.compute(smooth_method=\"floor\", smooth_value=0) \nresults[\"precisions\"] = [np.round(p, 2) for p in results[\"precisions\"]] \npd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])","metadata":{"execution":{"iopub.status.busy":"2024-02-29T03:46:31.694818Z","iopub.execute_input":"2024-02-29T03:46:31.695663Z","iopub.status.idle":"2024-02-29T03:46:46.403560Z","shell.execute_reply.started":"2024-02-29T03:46:31.695628Z","shell.execute_reply":"2024-02-29T03:46:46.402598Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting sacrebleu\n  Downloading sacrebleu-2.4.0-py3-none-any.whl.metadata (57 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting portalocker (from sacrebleu)\n  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2023.12.25)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (1.26.4)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (5.1.0)\nDownloading sacrebleu-2.4.0-py3-none-any.whl (106 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\nInstalling collected packages: portalocker, sacrebleu\nSuccessfully installed portalocker-2.8.2 sacrebleu-2.4.0\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                             Value\nscore                          0.0\ncounts                [2, 0, 0, 0]\ntotals                [6, 5, 4, 3]\nprecisions  [33.33, 0.0, 0.0, 0.0]\nbp                             1.0\nsys_len                          6\nref_len                          6","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>score</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>counts</th>\n      <td>[2, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>totals</th>\n      <td>[6, 5, 4, 3]</td>\n    </tr>\n    <tr>\n      <th>precisions</th>\n      <td>[33.33, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>bp</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>sys_len</th>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>ref_len</th>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"bleu_metric.add( prediction=\"the cat is on mat\", reference=[\"the cat is on the mat\"])\nresults = bleu_metric.compute(smooth_method=\"floor\", smooth_value=0) \nresults[\"precisions\"] = [np.round(p, 2)for p in results[\"precisions\"]] \npd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])","metadata":{"execution":{"iopub.status.busy":"2024-02-29T03:46:54.547477Z","iopub.execute_input":"2024-02-29T03:46:54.548178Z","iopub.status.idle":"2024-02-29T03:46:54.566559Z","shell.execute_reply.started":"2024-02-29T03:46:54.548143Z","shell.execute_reply":"2024-02-29T03:46:54.565575Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"                                 Value\nscore                        57.893007\ncounts                    [5, 3, 2, 1]\ntotals                    [5, 4, 3, 2]\nprecisions  [100.0, 75.0, 66.67, 50.0]\nbp                            0.818731\nsys_len                              5\nref_len                              6","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>score</th>\n      <td>57.893007</td>\n    </tr>\n    <tr>\n      <th>counts</th>\n      <td>[5, 3, 2, 1]</td>\n    </tr>\n    <tr>\n      <th>totals</th>\n      <td>[5, 4, 3, 2]</td>\n    </tr>\n    <tr>\n      <th>precisions</th>\n      <td>[100.0, 75.0, 66.67, 50.0]</td>\n    </tr>\n    <tr>\n      <th>bp</th>\n      <td>0.818731</td>\n    </tr>\n    <tr>\n      <th>sys_len</th>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>ref_len</th>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"!pip install rouge_score\nrouge_metric = load_metric(\"rouge\")\nreference = dataset[\"train\"][1][\"highlights\"] \nrecords = [] \nrouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"] \nfor model_name in summaries: \n\trouge_metric.add(prediction=summaries[model_name], reference=reference) \n\tscore = rouge_metric.compute() \n\trouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n\trecords.append(rouge_dict) \npd.DataFrame.from_records(records, index=summaries.keys())","metadata":{"execution":{"iopub.status.busy":"2024-02-29T03:47:15.159304Z","iopub.execute_input":"2024-02-29T03:47:15.159933Z","iopub.status.idle":"2024-02-29T03:47:31.619292Z","shell.execute_reply.started":"2024-02-29T03:47:15.159900Z","shell.execute_reply":"2024-02-29T03:47:31.618263Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=418a2acefc9f933eb421bcf0fa2c219c0e56d6c2934107980665978598c3ca18\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"            rouge1    rouge2    rougeL  rougeLsum\nbaseline  0.303571  0.090909  0.214286   0.232143\ngpt2      0.212121  0.000000  0.121212   0.212121\nt5        0.486486  0.222222  0.378378   0.486486\nbart      0.582278  0.207792  0.455696   0.506329\npegasus   0.866667  0.655172  0.800000   0.833333","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rouge1</th>\n      <th>rouge2</th>\n      <th>rougeL</th>\n      <th>rougeLsum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>baseline</th>\n      <td>0.303571</td>\n      <td>0.090909</td>\n      <td>0.214286</td>\n      <td>0.232143</td>\n    </tr>\n    <tr>\n      <th>gpt2</th>\n      <td>0.212121</td>\n      <td>0.000000</td>\n      <td>0.121212</td>\n      <td>0.212121</td>\n    </tr>\n    <tr>\n      <th>t5</th>\n      <td>0.486486</td>\n      <td>0.222222</td>\n      <td>0.378378</td>\n      <td>0.486486</td>\n    </tr>\n    <tr>\n      <th>bart</th>\n      <td>0.582278</td>\n      <td>0.207792</td>\n      <td>0.455696</td>\n      <td>0.506329</td>\n    </tr>\n    <tr>\n      <th>pegasus</th>\n      <td>0.866667</td>\n      <td>0.655172</td>\n      <td>0.800000</td>\n      <td>0.833333</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def evaluate_summaries_baseline(dataset, metric, column_text=\"article\", \t\t\tcolumn_summary=\"highlights\"): \n    summaries = [three_sentence_summary(text) for text in dataset[column_text]] \n    metric.add_batch(predictions=summaries, references=dataset[column_summary]) \n    score = metric.compute() \n    return score","metadata":{"execution":{"iopub.status.busy":"2024-02-29T03:47:40.563659Z","iopub.execute_input":"2024-02-29T03:47:40.564076Z","iopub.status.idle":"2024-02-29T03:47:40.569872Z","shell.execute_reply.started":"2024-02-29T03:47:40.564040Z","shell.execute_reply":"2024-02-29T03:47:40.568862Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"test_sampled = dataset[\"test\"].shuffle(seed=42).select(range(1000)) \nscore = evaluate_summaries_baseline(test_sampled, rouge_metric) \nrouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names) \npd.DataFrame.from_dict(rouge_dict, orient=\"index\", columns=[\"baseline\"]).T\n","metadata":{"execution":{"iopub.status.busy":"2024-02-29T03:47:58.925305Z","iopub.execute_input":"2024-02-29T03:47:58.925668Z","iopub.status.idle":"2024-02-29T03:48:07.611482Z","shell.execute_reply.started":"2024-02-29T03:47:58.925637Z","shell.execute_reply":"2024-02-29T03:48:07.610258Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"            rouge1    rouge2    rougeL  rougeLsum\nbaseline  0.388071  0.170554  0.247146   0.354972","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rouge1</th>\n      <th>rouge2</th>\n      <th>rougeL</th>\n      <th>rougeLsum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>baseline</th>\n      <td>0.388071</td>\n      <td>0.170554</td>\n      <td>0.247146</td>\n      <td>0.354972</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from tqdm import tqdm \nimport torch \ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\" \ndef chunks(list_of_elements, batch_size):  \n    \"\"\"Yield successive batch-sized chunks from list_of_elements.\"\"\"  \n    for i in range(0, len(list_of_elements), batch_size):  \n        yield list_of_elements[i:i + batch_size]\ndef evaluate_summaries_pegasus(dataset, metric, model, tokenizer, batch_size=16, device=device, column_text=\"article\", column_summary=\"highlights\"): \n\tarticle_batches = list(chunks(dataset[column_text], batch_size)) \n\ttarget_batches = list(chunks(dataset[column_summary], batch_size)) \n\tfor article_batch, target_batch in tqdm( zip(article_batches, target_batches), total=len(article_batches)): \n\t\tinputs = tokenizer(article_batch, max_length=1024, truncation=True, padding=\"max_length\", return_tensors=\"pt\") \n\t\tsummaries = model.generate(input_ids=inputs[\"input_ids\"].to(device), attention_mask=inputs[\"attention_mask\"].to(device), length_penalty=0.8, num_beams=8, max_length=128) \n\t\tdecoded_summaries = [tokenizer.decode(s, skip_special_tokens=True, clean_up_tokenization_spaces=True) for s in summaries] \n\t\tdecoded_summaries = [d.replace(\"<n>\", \" \") for d in decoded_summaries] \n\t\tmetric.add_batch(predictions=decoded_summaries, references=target_batch) \n\tscore = metric.compute() \n\treturn score","metadata":{"execution":{"iopub.status.busy":"2024-02-29T03:49:20.925775Z","iopub.execute_input":"2024-02-29T03:49:20.926180Z","iopub.status.idle":"2024-02-29T03:49:21.016032Z","shell.execute_reply.started":"2024-02-29T03:49:20.926146Z","shell.execute_reply":"2024-02-29T03:49:21.014870Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer \nmodel_ckpt = \"google/pegasus-cnn_dailymail\" \ntokenizer = AutoTokenizer.from_pretrained(model_ckpt) \nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device) \nscore = evaluate_summaries_pegasus(test_sampled, rouge_metric, model, tokenizer, batch_size=8) \nrouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names) \npd.DataFrame(rouge_dict, index=[\"pegasus\"])","metadata":{"execution":{"iopub.status.busy":"2024-02-29T03:49:23.917927Z","iopub.execute_input":"2024-02-29T03:49:23.918881Z","iopub.status.idle":"2024-02-29T04:13:48.569219Z","shell.execute_reply.started":"2024-02-29T03:49:23.918846Z","shell.execute_reply":"2024-02-29T04:13:48.568270Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [24:07<00:00, 11.58s/it]\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"           rouge1    rouge2    rougeL  rougeLsum\npegasus  0.427195  0.207378  0.305054    0.36919","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rouge1</th>\n      <th>rouge2</th>\n      <th>rougeL</th>\n      <th>rougeLsum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>pegasus</th>\n      <td>0.427195</td>\n      <td>0.207378</td>\n      <td>0.305054</td>\n      <td>0.36919</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"!pip install py7zr\nfrom datasets import load_dataset\ndataset_samsum = load_dataset(\"samsum\") \nsplit_lengths = [len(dataset_samsum[split])for split in dataset_samsum] \nprint(f\"Split lengths: {split_lengths}\") \nprint(f\"Features: {dataset_samsum['train'].column_names}\") \nprint(\"\\nDialogue:\") \nprint(dataset_samsum[\"test\"][0][\"dialogue\"]) \nprint(\"\\nSummary:\") \nprint(dataset_samsum[\"test\"][0][\"summary\"])","metadata":{"execution":{"iopub.status.busy":"2024-02-29T04:15:08.648470Z","iopub.execute_input":"2024-02-29T04:15:08.648832Z","iopub.status.idle":"2024-02-29T04:15:41.338024Z","shell.execute_reply.started":"2024-02-29T04:15:08.648802Z","shell.execute_reply":"2024-02-29T04:15:41.337105Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting py7zr\n  Downloading py7zr-0.20.8-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: texttable in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.7.0)\nCollecting pycryptodomex>=3.16.0 (from py7zr)\n  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\nCollecting pyzstd>=0.15.9 (from py7zr)\n  Downloading pyzstd-0.15.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\nCollecting pyppmd<1.2.0,>=1.1.0 (from py7zr)\n  Downloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\nCollecting pybcj<1.1.0,>=1.0.0 (from py7zr)\n  Downloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\nCollecting multivolumefile>=0.2.3 (from py7zr)\n  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\nCollecting inflate64<1.1.0,>=1.0.0 (from py7zr)\n  Downloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\nCollecting brotli>=1.1.0 (from py7zr)\n  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.5 kB)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from py7zr) (5.9.3)\nDownloading py7zr-0.20.8-py3-none-any.whl (67 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\nDownloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m138.9/138.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyzstd-0.15.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (412 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m412.3/412.3 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: brotli, pyzstd, pyppmd, pycryptodomex, pybcj, multivolumefile, inflate64, py7zr\n  Attempting uninstall: brotli\n    Found existing installation: Brotli 1.0.9\n    Uninstalling Brotli-1.0.9:\n      Successfully uninstalled Brotli-1.0.9\nSuccessfully installed brotli-1.1.0 inflate64-1.0.0 multivolumefile-0.2.3 py7zr-0.20.8 pybcj-1.0.2 pycryptodomex-3.20.0 pyppmd-1.1.0 pyzstd-0.15.9\nDownloading and preparing dataset samsum/samsum (download: 2.81 MiB, generated: 10.04 MiB, post-processed: Unknown size, total: 12.85 MiB) to /root/.cache/huggingface/datasets/samsum/samsum/0.0.0/3f7dba43be72ab10ca66a2e0f8547b3590e96c2bd9f2cbb1f6bb1ec1f1488ba6...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/2.94M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29ecb7c150c24204a9c05461e8af8ccc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/14732 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/819 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/818 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset samsum downloaded and prepared to /root/.cache/huggingface/datasets/samsum/samsum/0.0.0/3f7dba43be72ab10ca66a2e0f8547b3590e96c2bd9f2cbb1f6bb1ec1f1488ba6. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce54b9f9f8ba419bad50821ab4ab96e6"}},"metadata":{}},{"name":"stdout","text":"Split lengths: [14732, 819, 818]\nFeatures: ['id', 'dialogue', 'summary']\n\nDialogue:\nHannah: Hey, do you have Betty's number?\nAmanda: Lemme check\nHannah: <file_gif>\nAmanda: Sorry, can't find it.\nAmanda: Ask Larry\nAmanda: He called her last time we were at the park together\nHannah: I don't know him well\nHannah: <file_gif>\nAmanda: Don't be shy, he's very nice\nHannah: If you say so..\nHannah: I'd rather you texted him\nAmanda: Just text him ğŸ™‚\nHannah: Urgh.. Alright\nHannah: Bye\nAmanda: Bye bye\n\nSummary:\nHannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\n","output_type":"stream"}]},{"cell_type":"code","source":"pipe_out = pipe(dataset_samsum[\"test\"][0][\"dialogue\"]) \nprint(\"Summary:\") \nprint(pipe_out[0][\"summary_text\"].replace(\" .<n>\", \".\\n\")) ","metadata":{"execution":{"iopub.status.busy":"2024-02-29T04:15:48.083605Z","iopub.execute_input":"2024-02-29T04:15:48.084020Z","iopub.status.idle":"2024-02-29T04:16:00.784990Z","shell.execute_reply.started":"2024-02-29T04:15:48.083960Z","shell.execute_reply":"2024-02-29T04:16:00.783852Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"Your max_length is set to 128, but your input_length is only 122. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=61)\n","output_type":"stream"},{"name":"stdout","text":"Summary:\nAmanda: Ask Larry Amanda: He called her last time we were at the park together.\nHannah: I'd rather you texted him.\nAmanda: Just text him .\n","output_type":"stream"}]},{"cell_type":"code","source":"score = evaluate_summaries_pegasus(dataset_samsum[\"test\"], rouge_metric, model, tokenizer, column_text=\"dialogue\", column_summary=\"summary\", batch_size=8) \nrouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names) \npd.DataFrame(rouge_dict, index=[\"pegasus\"])","metadata":{"execution":{"iopub.status.busy":"2024-02-29T04:16:06.543683Z","iopub.execute_input":"2024-02-29T04:16:06.544058Z","iopub.status.idle":"2024-02-29T04:34:07.787852Z","shell.execute_reply.started":"2024-02-29T04:16:06.544025Z","shell.execute_reply":"2024-02-29T04:34:07.786889Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [17:59<00:00, 10.48s/it]\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"           rouge1    rouge2    rougeL  rougeLsum\npegasus  0.296091  0.087493  0.229237   0.229642","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rouge1</th>\n      <th>rouge2</th>\n      <th>rougeL</th>\n      <th>rougeLsum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>pegasus</th>\n      <td>0.296091</td>\n      <td>0.087493</td>\n      <td>0.229237</td>\n      <td>0.229642</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nd_len = [len(tokenizer.encode(s)) for s in dataset_samsum[\"train\"] [\"dialogue\"]] \ns_len = [len(tokenizer.encode(s)) for s in dataset_samsum[\"train\"][\"summary\"]] \nfig, axes = plt.subplots(1, 2, figsize=(10, 3.5), sharey=True)\naxes[0].hist(d_len, bins=20, color=\"C0\", edgecolor=\"C0\") \naxes[0].set_title(\"Dialogue Token Length\") \naxes[0].set_xlabel(\"Length\") \naxes[0].set_ylabel(\"Count\") \naxes[1].hist(s_len, bins=20, color=\"C0\", edgecolor=\"C0\") \naxes[1].set_title(\"Summary Token Length\") \naxes[1].set_xlabel(\"Length\") \nplt.tight_layout() \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-29T04:35:30.595405Z","iopub.execute_input":"2024-02-29T04:35:30.595768Z","iopub.status.idle":"2024-02-29T04:35:42.443920Z","shell.execute_reply.started":"2024-02-29T04:35:30.595737Z","shell.execute_reply":"2024-02-29T04:35:42.442930Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x350 with 2 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"def convert_examples_to_features(example_batch): \n\tinput_encodings = tokenizer(example_batch[\"dialogue\"], max_length=1024, truncation=True) \n\twith tokenizer.as_target_tokenizer(): \n\t\ttarget_encodings = tokenizer(example_batch[\"summary\"], max_length=128, truncation=True) \n\treturn {\"input_ids\": input_encodings[\"input_ids\"], \"attention_mask\": input_encodings[\"attention_mask\"], \"labels\": target_encodings[\"input_ids\"]} \ndataset_samsum_pt = dataset_samsum.map(convert_examples_to_features, batched=True) \ncolumns = [\"input_ids\", \"labels\", \"attention_mask\"] \ndataset_samsum_pt.set_format(type=\"torch\", columns=columns)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq \nseq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model) \n#ç„¶åï¼Œåƒå¾€å¸¸ä¸€æ ·ï¼Œæˆ‘ä»¬ä¸ºè®­ç»ƒè®¾ç½®äº†ä¸€ä¸ªTrainingArguments:\nfrom transformers import TrainingArguments, Trainer \ntraining_args = TrainingArguments( output_dir='pegasus-samsum', num_train_epochs=1, warmup_steps=500, per_device_train_batch_size=1, per_device_eval_batch_size=1, weight_decay=0.01, logging_steps=10, push_to_hub=True,\nevaluation_strategy='steps', eval_steps=500, save_steps=1e6, gradient_accumulation_steps=16)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(model=model, args=training_args, tokenizer=tokenizer, data_collator=seq2seq_data_collator, train_dataset=dataset_samsum_pt[\"train\"], eval_dataset=dataset_samsum_pt[\"validation\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train() \nscore = evaluate_summaries_pegasus( dataset_samsum[\"test\"], rouge_metric, trainer.model, tokenizer, batch_size=2, column_text=\"dialogue\", column_summary=\"summary\") \nrouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names) pd.DataFrame(rouge_dict, index=[f\"pegasus\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gen_kwargs = {\"length_penalty\": 0.8, \"num_beams\":8, \"max_length\": 128} \nsample_text = dataset_samsum[\"test\"][0][\"dialogue\"] \nreference = dataset_samsum[\"test\"][0][\"summary\"] \npipe = pipeline(\"summarization\", model=\"transformersbook/pegasus-samsum\") print(\"Dialogue:\") \nprint(sample_text) \nprint(\"\\nReference Summary:\") \nprint(reference) \nprint(\"\\nModel Summary:\") \nprint(pipe(sample_text, **gen_kwargs)[0][\"summary_text\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import pandas as pd \ndataset_url = \"https://git.io/nlp-with-transformers\" \ndf_issues = pd.read_json(dataset_url, lines=True) \nprint(f\"DataFrame shape: {df_issues.shape}\") ","metadata":{"execution":{"iopub.status.busy":"2024-02-29T04:49:26.808398Z","iopub.execute_input":"2024-02-29T04:49:26.809049Z","iopub.status.idle":"2024-02-29T04:49:30.507689Z","shell.execute_reply.started":"2024-02-29T04:49:26.809006Z","shell.execute_reply":"2024-02-29T04:49:30.506713Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"DataFrame shape: (9930, 26)\n","output_type":"stream"}]},{"cell_type":"code","source":"cols = [\"url\", \"id\", \"title\", \"user\", \"labels\", \"state\", \"created_at\", \"body\"] \n\ndf_issues.loc[2, cols].to_frame()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-29T04:49:42.520130Z","iopub.execute_input":"2024-02-29T04:49:42.520508Z","iopub.status.idle":"2024-02-29T04:49:42.541436Z","shell.execute_reply.started":"2024-02-29T04:49:42.520477Z","shell.execute_reply":"2024-02-29T04:49:42.540345Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"                                                            2\nurl         https://api.github.com/repos/huggingface/trans...\nid                                                  849529761\ntitle       [DeepSpeed] ZeRO stage 3 integration: getting ...\nuser        {'login': 'stas00', 'id': 10676103, 'node_id':...\nlabels      [{'id': 2659267025, 'node_id': 'MDU6TGFiZWwyNj...\nstate                                                    open\ncreated_at                                2021-04-02 23:40:42\nbody        **[This is not yet alive, preparing for the re...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>url</th>\n      <td>https://api.github.com/repos/huggingface/trans...</td>\n    </tr>\n    <tr>\n      <th>id</th>\n      <td>849529761</td>\n    </tr>\n    <tr>\n      <th>title</th>\n      <td>[DeepSpeed] ZeRO stage 3 integration: getting ...</td>\n    </tr>\n    <tr>\n      <th>user</th>\n      <td>{'login': 'stas00', 'id': 10676103, 'node_id':...</td>\n    </tr>\n    <tr>\n      <th>labels</th>\n      <td>[{'id': 2659267025, 'node_id': 'MDU6TGFiZWwyNj...</td>\n    </tr>\n    <tr>\n      <th>state</th>\n      <td>open</td>\n    </tr>\n    <tr>\n      <th>created_at</th>\n      <td>2021-04-02 23:40:42</td>\n    </tr>\n    <tr>\n      <th>body</th>\n      <td>**[This is not yet alive, preparing for the re...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# ç¬¬ï¼—ç«  é—®ç­”ç³»ç»Ÿ","metadata":{}},{"cell_type":"code","source":"!pip install datasets\n!pip install transformers[torch]\n!pip install accelerate -U","metadata":{"execution":{"iopub.status.busy":"2024-02-29T11:30:20.274791Z","iopub.execute_input":"2024-02-29T11:30:20.275142Z","iopub.status.idle":"2024-02-29T11:30:58.873805Z","shell.execute_reply.started":"2024-02-29T11:30:20.275105Z","shell.execute_reply":"2024-02-29T11:30:58.872731Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->datasets) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.20.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.13.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.38.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.20.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.66.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.1.2)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.27.2)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.3)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.27.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.20.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import get_dataset_config_names\ndomains = get_dataset_config_names(\"subjqa\")","metadata":{"execution":{"iopub.status.busy":"2024-02-29T11:31:27.864722Z","iopub.execute_input":"2024-02-29T11:31:27.865101Z","iopub.status.idle":"2024-02-29T11:31:30.210688Z","shell.execute_reply.started":"2024-02-29T11:31:27.865069Z","shell.execute_reply":"2024-02-29T11:31:30.209932Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.65k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a52cc9cae78e45d2ba18a93d800653a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/1.46k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efe2d7e413f34632aa58880fb94dff3c"}},"metadata":{}}]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nfrom datasets import load_dataset\nsubjqa = load_dataset(\"subjqa\", name=\"electronics\")","metadata":{"execution":{"iopub.status.busy":"2024-02-29T11:33:06.064731Z","iopub.execute_input":"2024-02-29T11:33:06.065440Z","iopub.status.idle":"2024-02-29T11:33:06.365772Z","shell.execute_reply.started":"2024-02-29T11:33:06.065406Z","shell.execute_reply":"2024-02-29T11:33:06.364678Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91bbc867f6b44438b655b0e60b60cd6b"}},"metadata":{}}]},{"cell_type":"code","source":"print(subjqa[\"train\"][\"answers\"][1])","metadata":{"execution":{"iopub.status.busy":"2024-02-29T11:33:09.166080Z","iopub.execute_input":"2024-02-29T11:33:09.166750Z","iopub.status.idle":"2024-02-29T11:33:09.211667Z","shell.execute_reply.started":"2024-02-29T11:33:09.166717Z","shell.execute_reply":"2024-02-29T11:33:09.210804Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"{'text': ['Bass is weak as expected', 'Bass is weak as expected, even with EQ adjusted up'], 'answer_start': [1302, 1302], 'answer_subj_level': [1, 1], 'ans_subj_score': [0.5083333253860474, 0.5083333253860474], 'is_ans_subjective': [True, True]}\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\ndfs = {split: dset.to_pandas() for split, dset in subjqa.flatten().items()}\nfor split, df in dfs.items():\n\tprint(f\"Number of questions in {split}: {df['id'].nunique()}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-29T11:33:11.175922Z","iopub.execute_input":"2024-02-29T11:33:11.176764Z","iopub.status.idle":"2024-02-29T11:33:11.220410Z","shell.execute_reply.started":"2024-02-29T11:33:11.176732Z","shell.execute_reply":"2024-02-29T11:33:11.219500Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Number of questions in train: 1295\nNumber of questions in test: 358\nNumber of questions in validation: 255\n","output_type":"stream"}]},{"cell_type":"code","source":"qa_cols = [\"title\", \"question\", \"answers.text\", \"answers.answer_start\", \"context\"]\nsample_df = dfs[\"train\"][qa_cols].sample(2, random_state=7)\nsample_df","metadata":{"execution":{"iopub.status.busy":"2024-02-29T11:33:13.263702Z","iopub.execute_input":"2024-02-29T11:33:13.264089Z","iopub.status.idle":"2024-02-29T11:33:13.289259Z","shell.execute_reply.started":"2024-02-29T11:33:13.264059Z","shell.execute_reply":"2024-02-29T11:33:13.288319Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"           title                        question                answers.text  \\\n791   B005DKZTMG  Does the keyboard lightweight?  [this keyboard is compact]   \n1159  B00AAIPT76             How is the battery?                          []   \n\n     answers.answer_start                                            context  \n791                 [215]  I really like this keyboard.  I give it 4 star...  \n1159                   []  I bought this after the first spare gopro batt...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>question</th>\n      <th>answers.text</th>\n      <th>answers.answer_start</th>\n      <th>context</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>791</th>\n      <td>B005DKZTMG</td>\n      <td>Does the keyboard lightweight?</td>\n      <td>[this keyboard is compact]</td>\n      <td>[215]</td>\n      <td>I really like this keyboard.  I give it 4 star...</td>\n    </tr>\n    <tr>\n      <th>1159</th>\n      <td>B00AAIPT76</td>\n      <td>How is the battery?</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>I bought this after the first spare gopro batt...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"start_idx = sample_df[\"answers.answer_start\"].iloc[0][0]\nend_idx = start_idx + len(sample_df[\"answers.text\"].iloc[0][0])\nsample_df[\"context\"].iloc[0][start_idx:end_idx]","metadata":{"execution":{"iopub.status.busy":"2024-02-29T11:37:21.763101Z","iopub.execute_input":"2024-02-29T11:37:21.763480Z","iopub.status.idle":"2024-02-29T11:37:21.770586Z","shell.execute_reply.started":"2024-02-29T11:37:21.763450Z","shell.execute_reply":"2024-02-29T11:37:21.769727Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"'this keyboard is compact'"},"metadata":{}}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ncounts = {}\nquestion_types = [\"What\", \"How\", \"Is\", \"Does\", \"Do\", \"Was\", \"Where\", \"Why\"]\nfor q in question_types:\n\tcounts[q] = dfs[\"train\"][\"question\"].str.startswith(q).value_counts()\n\npd.Series(counts)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T11:37:34.639163Z","iopub.execute_input":"2024-02-29T11:37:34.639532Z","iopub.status.idle":"2024-02-29T11:37:34.666290Z","shell.execute_reply.started":"2024-02-29T11:37:34.639503Z","shell.execute_reply":"2024-02-29T11:37:34.665217Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"What     question\nFalse    1059\nTrue      236\nName: cou...\nHow      question\nTrue     780\nFalse    515\nName: count...\nIs       question\nFalse    1195\nTrue      100\nName: cou...\nDoes     question\nFalse    1250\nTrue       45\nName: cou...\nDo       question\nFalse    1212\nTrue       83\nName: cou...\nWas      question\nFalse    1283\nTrue       12\nName: cou...\nWhere    question\nFalse    1267\nTrue       28\nName: cou...\nWhy      question\nFalse    1274\nTrue       21\nName: cou...\ndtype: object"},"metadata":{}}]},{"cell_type":"code","source":"for question_type in [\"How\", \"What\", \"Is\"]:\n\tfor question in ( dfs[\"train\"][dfs[\"train\"].question.str.startswith(question_type)] .sample(n=3, random_state=42)['question']):\n\t\tprint(question)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T11:37:41.439195Z","iopub.execute_input":"2024-02-29T11:37:41.439883Z","iopub.status.idle":"2024-02-29T11:37:41.456957Z","shell.execute_reply.started":"2024-02-29T11:37:41.439850Z","shell.execute_reply":"2024-02-29T11:37:41.455682Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"How is the camera?\nHow do you like the control?\nHow fast is the charger?\nWhat is direction?\nWhat is the quality of the construction of the bag?\nWhat is your impression of the product?\nIs this how zoom works?\nIs sound clear?\nIs it a wireless keyboard?\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\nmodel_ckpt = \"deepset/minilm-uncased-squad2\"\ntokenizer = AutoTokenizer.from_pretrained(model_ckpt)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T11:37:43.986432Z","iopub.execute_input":"2024-02-29T11:37:43.986798Z","iopub.status.idle":"2024-02-29T11:37:48.788395Z","shell.execute_reply.started":"2024-02-29T11:37:43.986769Z","shell.execute_reply":"2024-02-29T11:37:48.787302Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/107 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11e94e148cba4e2085d53151a1ec9080"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/477 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63d8464c14984ddd9936633a0fa689c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52db05a295dd4e44a9386c8dedbe50eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c05fb9b990849e98294b0842b885ee4"}},"metadata":{}}]},{"cell_type":"code","source":"uestion = \"How much music can this hold?\"\ncontext = \"\"\"An MP3 is about 1 MB/minute, so about 6000 hours depending on \\ file size.\"\"\"\ninputs = tokenizer(question, context, return_tensors=\"pt\")\n","metadata":{"execution":{"iopub.status.busy":"2024-02-29T11:38:06.276021Z","iopub.execute_input":"2024-02-29T11:38:06.276607Z","iopub.status.idle":"2024-02-29T11:38:06.303317Z","shell.execute_reply.started":"2024-02-29T11:38:06.276577Z","shell.execute_reply":"2024-02-29T11:38:06.302513Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print(tokenizer.decode(inputs[\"input_ids\"][0]))","metadata":{"execution":{"iopub.status.busy":"2024-02-29T11:38:08.831556Z","iopub.execute_input":"2024-02-29T11:38:08.831945Z","iopub.status.idle":"2024-02-29T11:38:08.855153Z","shell.execute_reply.started":"2024-02-29T11:38:08.831914Z","shell.execute_reply":"2024-02-29T11:38:08.854173Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"[CLS] is it a wireless keyboard? [SEP] an mp3 is about 1 mb / minute, so about 6000 hours depending on \\ file size. [SEP]\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForQuestionAnswering\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_ckpt)\nwith torch.no_grad():\n\toutputs = model(**inputs)\n\tprint(outputs)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T11:38:10.463242Z","iopub.execute_input":"2024-02-29T11:38:10.463577Z","iopub.status.idle":"2024-02-29T11:38:13.172861Z","shell.execute_reply.started":"2024-02-29T11:38:10.463553Z","shell.execute_reply":"2024-02-29T11:38:13.171697Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a442633a32f54544a73540fb3edb249a"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at deepset/minilm-uncased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"name":"stdout","text":"QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[ 2.8510, -5.0135, -5.2084, -4.0294, -2.8482, -3.7303, -6.0579,  2.8510,\n         -2.4657, -0.8893, -4.6217, -2.2798, -1.9392, -4.8937, -5.5844, -4.9004,\n         -5.9556, -3.8715, -2.7315, -2.5275, -4.7680, -4.3791, -5.6296, -3.9556,\n         -4.7228, -5.0144, -5.3759,  2.8510]]), end_logits=tensor([[ 3.1789, -6.0457, -5.2371, -5.2178, -4.9497, -0.8735, -3.3717,  3.1788,\n         -5.2578, -0.6590, -5.3717, -5.7263, -4.6543, -4.8667, -5.8881, -2.6058,\n         -2.7214, -4.7760, -6.1632, -4.1363, -2.3603, -4.7872, -5.8269, -5.1322,\n         -5.5225, -1.9867, -2.1770,  3.1788]]), hidden_states=None, attentions=None)\n","output_type":"stream"}]},{"cell_type":"code","source":"start_logits = outputs.start_logits\nend_logits = outputs.end_logits\n     ","metadata":{"execution":{"iopub.status.busy":"2024-02-29T11:38:15.244134Z","iopub.execute_input":"2024-02-29T11:38:15.245372Z","iopub.status.idle":"2024-02-29T11:38:15.251920Z","shell.execute_reply.started":"2024-02-29T11:38:15.245330Z","shell.execute_reply":"2024-02-29T11:38:15.251025Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print(f\"Input IDs shape: {inputs.input_ids.size()}\")\nprint(f\"Start logits shape: {start_logits.size()}\")\nprint(f\"End logits shape: {end_logits.size()}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-29T11:38:17.905675Z","iopub.execute_input":"2024-02-29T11:38:17.906420Z","iopub.status.idle":"2024-02-29T11:38:17.911155Z","shell.execute_reply.started":"2024-02-29T11:38:17.906387Z","shell.execute_reply":"2024-02-29T11:38:17.910164Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Input IDs shape: torch.Size([1, 28])\nStart logits shape: torch.Size([1, 28])\nEnd logits shape: torch.Size([1, 28])\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nstart_idx = torch.argmax(start_logits)\nend_idx = torch.argmax(end_logits) + 1\nanswer_span = inputs[\"input_ids\"][0][start_idx:end_idx]\nanswer = tokenizer.decode(answer_span)\nprint(f\"Question: {question}\")\nprint(f\"Answer: {answer}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-29T11:38:20.188074Z","iopub.execute_input":"2024-02-29T11:38:20.188957Z","iopub.status.idle":"2024-02-29T11:38:20.199919Z","shell.execute_reply.started":"2024-02-29T11:38:20.188921Z","shell.execute_reply":"2024-02-29T11:38:20.198905Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Question: Is it a wireless keyboard?\nAnswer: [CLS]\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import pipeline\npipe = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\npipe(question=question, context=context, topk=3)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T11:38:22.070074Z","iopub.execute_input":"2024-02-29T11:38:22.070778Z","iopub.status.idle":"2024-02-29T11:38:35.771225Z","shell.execute_reply.started":"2024-02-29T11:38:22.070747Z","shell.execute_reply":"2024-02-29T11:38:35.770208Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"2024-02-29 11:38:24.280964: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-29 11:38:24.281077: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-29 11:38:24.457525: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/question_answering.py:326: UserWarning: topk parameter is deprecated, use top_k instead\n  warnings.warn(\"topk parameter is deprecated, use top_k instead\", UserWarning)\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.00046262488467618823, 'start': 3, 'end': 6, 'answer': 'MP3'},\n {'score': 9.562843479216099e-05, 'start': 0, 'end': 6, 'answer': 'An MP3'},\n {'score': 8.440116653218865e-05,\n  'start': 3,\n  'end': 48,\n  'answer': 'MP3 is about 1 MB/minute, so about 6000 hours'}]"},"metadata":{}}]},{"cell_type":"code","source":"pipe(question=\"Why is there no data?\", context=context, handle_impossible_answer=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T11:38:37.541114Z","iopub.execute_input":"2024-02-29T11:38:37.541923Z","iopub.status.idle":"2024-02-29T11:38:37.595843Z","shell.execute_reply.started":"2024-02-29T11:38:37.541890Z","shell.execute_reply":"2024-02-29T11:38:37.594786Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"{'score': 0.9193897247314453, 'start': 0, 'end': 0, 'answer': ''}"},"metadata":{}}]},{"cell_type":"code","source":"example = dfs[\"train\"].iloc[0][[\"question\", \"context\"]]\ntokenized_example = tokenizer(example[\"question\"], example[\"context\"], return_overflowing_tokens=True, max_length=100, stride=25)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T11:38:39.304389Z","iopub.execute_input":"2024-02-29T11:38:39.304759Z","iopub.status.idle":"2024-02-29T11:38:39.313039Z","shell.execute_reply.started":"2024-02-29T11:38:39.304731Z","shell.execute_reply":"2024-02-29T11:38:39.311981Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","output_type":"stream"}]},{"cell_type":"code","source":"for idx, window in enumerate(tokenized_example[\"input_ids\"]):\n  print(f\"Window #{idx} has {len(window)} tokens\")","metadata":{"execution":{"iopub.status.busy":"2024-02-29T11:38:42.210870Z","iopub.execute_input":"2024-02-29T11:38:42.211664Z","iopub.status.idle":"2024-02-29T11:38:42.217239Z","shell.execute_reply.started":"2024-02-29T11:38:42.211629Z","shell.execute_reply":"2024-02-29T11:38:42.216137Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Window #0 has 100 tokens\nWindow #1 has 88 tokens\n","output_type":"stream"}]},{"cell_type":"code","source":"for window in tokenized_example[\"input_ids\"]:\n\tprint(f\"{tokenizer.decode(window)} \\n\")","metadata":{"execution":{"iopub.status.busy":"2024-02-29T11:38:44.250550Z","iopub.execute_input":"2024-02-29T11:38:44.251490Z","iopub.status.idle":"2024-02-29T11:38:44.258944Z","shell.execute_reply.started":"2024-02-29T11:38:44.251456Z","shell.execute_reply":"2024-02-29T11:38:44.257920Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"[CLS] how is the bass? [SEP] i have had koss headphones in the past, pro 4aa and qz - 99. the koss portapro is portable and has great bass response. the work great with my android phone and can be \" rolled up \" to be carried in my motorcycle jacket or computer bag without getting crunched. they are very light and do not feel heavy or bear down on your ears even after listening to music with them on all day. the sound is [SEP] \n\n[CLS] how is the bass? [SEP] and do not feel heavy or bear down on your ears even after listening to music with them on all day. the sound is night and day better than any ear - bud could be and are almost as good as the pro 4aa. they are \" open air \" headphones so you cannot match the bass to the sealed types, but it comes close. for $ 32, you cannot go wrong. [SEP] \n\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install haystack","metadata":{"execution":{"iopub.status.busy":"2024-02-29T11:38:46.627099Z","iopub.execute_input":"2024-02-29T11:38:46.627725Z","iopub.status.idle":"2024-02-29T11:39:02.507853Z","shell.execute_reply.started":"2024-02-29T11:38:46.627693Z","shell.execute_reply":"2024-02-29T11:39:02.506495Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Collecting haystack\n  Downloading haystack-0.42-py2.py3-none-any.whl (179 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m179.6/179.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting construct<2.8 (from haystack)\n  Downloading construct-2.5.3.tar.gz (688 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m688.1/688.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting pefile (from haystack)\n  Downloading pefile-2023.2.7-py3-none-any.whl.metadata (1.4 kB)\nCollecting python-ptrace>=0.8.1 (from haystack)\n  Downloading python_ptrace-0.9.8-py2.py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from construct<2.8->haystack) (1.16.0)\nDownloading python_ptrace-0.9.8-py2.py3-none-any.whl (99 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.7/99.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pefile-2023.2.7-py3-none-any.whl (71 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.8/71.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: construct\n  Building wheel for construct (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for construct: filename=construct-2.5.3-py2.py3-none-any.whl size=71819 sha256=35f1f4302898d7fb772a9424e81d413d3a0b2dfad7aede61e39989fc8c8cd335\n  Stored in directory: /root/.cache/pip/wheels/ce/16/f9/f48a4c1a687e0848495c1a95dd9a87a246974b9318240d140b\nSuccessfully built construct\nInstalling collected packages: python-ptrace, pefile, construct, haystack\nSuccessfully installed construct-2.5.3 haystack-0.42 pefile-2023.2.7 python-ptrace-0.9.8\n","output_type":"stream"}]},{"cell_type":"code","source":"url = \"\"\"https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.2-linux-x86_64.tar.gz\"\"\"\n!wget -nc -q {url}\n!tar -xzf elasticsearch-7.9.2-linux-x86_64.tar.gz","metadata":{"execution":{"iopub.status.busy":"2024-02-29T11:39:06.357570Z","iopub.execute_input":"2024-02-29T11:39:06.358600Z","iopub.status.idle":"2024-02-29T11:39:21.177063Z","shell.execute_reply.started":"2024-02-29T11:39:06.358563Z","shell.execute_reply":"2024-02-29T11:39:21.175273Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"import os\nfrom subprocess import Popen, PIPE, STDOUT\n# Run Elasticsearch as a background process\n!chown -R daemon:daemon elasticsearch-7.9.2\nes_server = Popen(args=['elasticsearch-7.9.2/bin/elasticsearch'], stdout=PIPE, stderr=STDOUT, preexec_fn=lambda: os.setuid(1))\n# Wait until Elasticsearch has started\n!sleep 30","metadata":{"execution":{"iopub.status.busy":"2024-02-29T11:39:25.979456Z","iopub.execute_input":"2024-02-29T11:39:25.980267Z","iopub.status.idle":"2024-02-29T11:39:58.109173Z","shell.execute_reply.started":"2024-02-29T11:39:25.980232Z","shell.execute_reply":"2024-02-29T11:39:58.107843Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"!curl -X GET \"localhost:9200/?pretty\"","metadata":{"execution":{"iopub.status.busy":"2024-02-29T11:39:59.993331Z","iopub.execute_input":"2024-02-29T11:39:59.994146Z","iopub.status.idle":"2024-02-29T11:40:01.064860Z","shell.execute_reply.started":"2024-02-29T11:39:59.994113Z","shell.execute_reply":"2024-02-29T11:40:01.063629Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"{\n  \"name\" : \"762d6ab19107\",\n  \"cluster_name\" : \"elasticsearch\",\n  \"cluster_uuid\" : \"lKiiaSf4Tua0-idlAGKUTQ\",\n  \"version\" : {\n    \"number\" : \"7.9.2\",\n    \"build_flavor\" : \"default\",\n    \"build_type\" : \"tar\",\n    \"build_hash\" : \"d34da0ea4a966c4e49417f2da2f244e3e97b4e6e\",\n    \"build_date\" : \"2020-09-23T00:45:33.626720Z\",\n    \"build_snapshot\" : false,\n    \"lucene_version\" : \"8.6.2\",\n    \"minimum_wire_compatibility_version\" : \"6.8.0\",\n    \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"\n  },\n  \"tagline\" : \"You Know, for Search\"\n}\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install farm-haystack[inference]","metadata":{"execution":{"iopub.status.busy":"2024-02-29T11:40:03.360180Z","iopub.execute_input":"2024-02-29T11:40:03.360624Z","iopub.status.idle":"2024-02-29T11:40:37.219702Z","shell.execute_reply.started":"2024-02-29T11:40:03.360588Z","shell.execute_reply":"2024-02-29T11:40:37.218530Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Collecting farm-haystack[inference]\n  Downloading farm_haystack-1.24.1-py3-none-any.whl.metadata (27 kB)\nCollecting boilerpy3 (from farm-haystack[inference])\n  Downloading boilerpy3-1.0.7-py3-none-any.whl.metadata (5.8 kB)\nCollecting events (from farm-haystack[inference])\n  Downloading Events-0.5-py3-none-any.whl.metadata (3.9 kB)\nRequirement already satisfied: httpx in /opt/conda/lib/python3.10/site-packages (from farm-haystack[inference]) (0.27.0)\nRequirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from farm-haystack[inference]) (4.20.0)\nCollecting lazy-imports==0.3.1 (from farm-haystack[inference])\n  Downloading lazy_imports-0.3.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from farm-haystack[inference]) (10.2.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from farm-haystack[inference]) (3.2.1)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from farm-haystack[inference]) (2.1.4)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from farm-haystack[inference]) (9.5.0)\nRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from farm-haystack[inference]) (4.2.0)\nCollecting posthog (from farm-haystack[inference])\n  Downloading posthog-3.4.2-py2.py3-none-any.whl.metadata (2.0 kB)\nCollecting prompthub-py==4.0.0 (from farm-haystack[inference])\n  Downloading prompthub_py-4.0.0-py3-none-any.whl.metadata (2.2 kB)\nCollecting pydantic<2 (from farm-haystack[inference])\n  Downloading pydantic-1.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (150 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m150.2/150.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting quantulum3 (from farm-haystack[inference])\n  Downloading quantulum3-0.9.0-py3-none-any.whl.metadata (14 kB)\nCollecting rank-bm25 (from farm-haystack[inference])\n  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from farm-haystack[inference]) (2.31.0)\nCollecting requests-cache<1.0.0 (from farm-haystack[inference])\n  Downloading requests_cache-0.9.8-py3-none-any.whl.metadata (8.7 kB)\nCollecting scikit-learn>=1.3.0 (from farm-haystack[inference])\n  Downloading scikit_learn-1.4.1.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nCollecting sseclient-py (from farm-haystack[inference])\n  Downloading sseclient_py-1.8.0-py2.py3-none-any.whl.metadata (2.0 kB)\nRequirement already satisfied: tenacity in /opt/conda/lib/python3.10/site-packages (from farm-haystack[inference]) (8.2.3)\nCollecting tiktoken>=0.5.1 (from farm-haystack[inference])\n  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from farm-haystack[inference]) (4.66.1)\nCollecting transformers==4.36.2 (from farm-haystack[inference])\n  Downloading transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m126.8/126.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: huggingface-hub>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[inference]) (0.20.3)\nCollecting sentence-transformers>=2.2.0 (from farm-haystack[inference])\n  Downloading sentence_transformers-2.4.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: pyyaml<7.0,>=6.0 in /opt/conda/lib/python3.10/site-packages (from prompthub-py==4.0.0->farm-haystack[inference]) (6.0.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2->farm-haystack[inference]) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2->farm-haystack[inference]) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2->farm-haystack[inference]) (21.3)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2->farm-haystack[inference]) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2->farm-haystack[inference]) (0.15.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2->farm-haystack[inference]) (0.4.2)\nRequirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece,torch]==4.36.2; extra == \"inference\"->farm-haystack[inference]) (0.2.0)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece,torch]==4.36.2; extra == \"inference\"->farm-haystack[inference]) (3.20.3)\nRequirement already satisfied: torch!=1.12.0,>=1.10 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece,torch]==4.36.2; extra == \"inference\"->farm-haystack[inference]) (2.1.2)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece,torch]==4.36.2; extra == \"inference\"->farm-haystack[inference]) (0.27.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.5.0->farm-haystack[inference]) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.5.0->farm-haystack[inference]) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->farm-haystack[inference]) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->farm-haystack[inference]) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->farm-haystack[inference]) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->farm-haystack[inference]) (2024.2.2)\nRequirement already satisfied: appdirs>=1.4.4 in /opt/conda/lib/python3.10/site-packages (from requests-cache<1.0.0->farm-haystack[inference]) (1.4.4)\nRequirement already satisfied: attrs>=21.2 in /opt/conda/lib/python3.10/site-packages (from requests-cache<1.0.0->farm-haystack[inference]) (23.2.0)\nCollecting cattrs>=22.2 (from requests-cache<1.0.0->farm-haystack[inference])\n  Downloading cattrs-23.2.3-py3-none-any.whl.metadata (10 kB)\nCollecting url-normalize>=1.4 (from requests-cache<1.0.0->farm-haystack[inference])\n  Downloading url_normalize-1.4.3-py2.py3-none-any.whl.metadata (3.1 kB)\nRequirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.3.0->farm-haystack[inference]) (1.11.4)\nRequirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.3.0->farm-haystack[inference]) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.3.0->farm-haystack[inference]) (3.2.0)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx->farm-haystack[inference]) (4.2.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx->farm-haystack[inference]) (1.0.4)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->farm-haystack[inference]) (1.3.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx->farm-haystack[inference]) (0.14.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->farm-haystack[inference]) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema->farm-haystack[inference]) (0.32.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->farm-haystack[inference]) (0.16.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->farm-haystack[inference]) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->farm-haystack[inference]) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->farm-haystack[inference]) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from posthog->farm-haystack[inference]) (1.16.0)\nCollecting monotonic>=1.5 (from posthog->farm-haystack[inference])\n  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: backoff>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from posthog->farm-haystack[inference]) (2.2.1)\nCollecting inflect (from quantulum3->farm-haystack[inference])\n  Downloading inflect-7.0.0-py3-none-any.whl.metadata (21 kB)\nCollecting num2words (from quantulum3->farm-haystack[inference])\n  Downloading num2words-0.5.13-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21.0->transformers[sentencepiece,torch]==4.36.2; extra == \"inference\"->farm-haystack[inference]) (5.9.3)\nRequirement already satisfied: exceptiongroup>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from cattrs>=22.2->requests-cache<1.0.0->farm-haystack[inference]) (1.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.36.2->farm-haystack[inference]) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[sentencepiece,torch]==4.36.2; extra == \"inference\"->farm-haystack[inference]) (1.12)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[sentencepiece,torch]==4.36.2; extra == \"inference\"->farm-haystack[inference]) (3.1.2)\nRequirement already satisfied: docopt>=0.6.2 in /opt/conda/lib/python3.10/site-packages (from num2words->quantulum3->farm-haystack[inference]) (0.6.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[sentencepiece,torch]==4.36.2; extra == \"inference\"->farm-haystack[inference]) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch!=1.12.0,>=1.10->transformers[sentencepiece,torch]==4.36.2; extra == \"inference\"->farm-haystack[inference]) (1.3.0)\nDownloading lazy_imports-0.3.1-py3-none-any.whl (12 kB)\nDownloading prompthub_py-4.0.0-py3-none-any.whl (6.9 kB)\nDownloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pydantic-1.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading requests_cache-0.9.8-py3-none-any.whl (48 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.7/48.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading scikit_learn-1.4.1.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading sentence_transformers-2.4.0-py3-none-any.whl (149 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m149.5/149.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading boilerpy3-1.0.7-py3-none-any.whl (22 kB)\nDownloading Events-0.5-py3-none-any.whl (6.8 kB)\nDownloading farm_haystack-1.24.1-py3-none-any.whl (768 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m768.2/768.2 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading posthog-3.4.2-py2.py3-none-any.whl (41 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading quantulum3-0.9.0-py3-none-any.whl (10.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\nDownloading sseclient_py-1.8.0-py2.py3-none-any.whl (8.8 kB)\nDownloading cattrs-23.2.3-py3-none-any.whl (57 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\nDownloading url_normalize-1.4.3-py2.py3-none-any.whl (6.8 kB)\nDownloading inflect-7.0.0-py3-none-any.whl (34 kB)\nDownloading num2words-0.5.13-py3-none-any.whl (143 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: sseclient-py, monotonic, events, url-normalize, rank-bm25, pydantic, num2words, lazy-imports, cattrs, boilerpy3, tiktoken, scikit-learn, requests-cache, prompthub-py, posthog, inflect, quantulum3, transformers, sentence-transformers, farm-haystack\n  Attempting uninstall: pydantic\n    Found existing installation: pydantic 2.5.3\n    Uninstalling pydantic-2.5.3:\n      Successfully uninstalled pydantic-2.5.3\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.2.2\n    Uninstalling scikit-learn-1.2.2:\n      Successfully uninstalled scikit-learn-1.2.2\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.38.1\n    Uninstalling transformers-4.38.1:\n      Successfully uninstalled transformers-4.38.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\nydata-profiling 4.6.4 requires pydantic>=2, but you have pydantic 1.10.14 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed boilerpy3-1.0.7 cattrs-23.2.3 events-0.5 farm-haystack-1.24.1 inflect-7.0.0 lazy-imports-0.3.1 monotonic-1.6 num2words-0.5.13 posthog-3.4.2 prompthub-py-4.0.0 pydantic-1.10.14 quantulum3-0.9.0 rank-bm25-0.2.2 requests-cache-0.9.8 scikit-learn-1.4.1.post1 sentence-transformers-2.4.0 sseclient-py-1.8.0 tiktoken-0.6.0 transformers-4.36.2 url-normalize-1.4.3\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install pydantic\nfrom pydantic import Field","metadata":{"execution":{"iopub.status.busy":"2024-02-29T11:41:43.422319Z","iopub.execute_input":"2024-02-29T11:41:43.422742Z","iopub.status.idle":"2024-02-29T11:41:55.942361Z","shell.execute_reply.started":"2024-02-29T11:41:43.422710Z","shell.execute_reply":"2024-02-29T11:41:55.941377Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pydantic in /opt/conda/lib/python3.10/site-packages (1.10.14)\nRequirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic) (4.9.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install farm-haystack[elasticsearch]","metadata":{"execution":{"iopub.status.busy":"2024-02-29T11:42:15.973477Z","iopub.execute_input":"2024-02-29T11:42:15.974190Z","iopub.status.idle":"2024-02-29T11:42:30.167239Z","shell.execute_reply.started":"2024-02-29T11:42:15.974152Z","shell.execute_reply":"2024-02-29T11:42:30.166075Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Requirement already satisfied: farm-haystack[elasticsearch] in /opt/conda/lib/python3.10/site-packages (1.24.1)\nRequirement already satisfied: boilerpy3 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[elasticsearch]) (1.0.7)\nRequirement already satisfied: events in /opt/conda/lib/python3.10/site-packages (from farm-haystack[elasticsearch]) (0.5)\nRequirement already satisfied: httpx in /opt/conda/lib/python3.10/site-packages (from farm-haystack[elasticsearch]) (0.27.0)\nRequirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from farm-haystack[elasticsearch]) (4.20.0)\nRequirement already satisfied: lazy-imports==0.3.1 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[elasticsearch]) (0.3.1)\nRequirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from farm-haystack[elasticsearch]) (10.2.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from farm-haystack[elasticsearch]) (3.2.1)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from farm-haystack[elasticsearch]) (2.1.4)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from farm-haystack[elasticsearch]) (9.5.0)\nRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from farm-haystack[elasticsearch]) (4.2.0)\nRequirement already satisfied: posthog in /opt/conda/lib/python3.10/site-packages (from farm-haystack[elasticsearch]) (3.4.2)\nRequirement already satisfied: prompthub-py==4.0.0 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[elasticsearch]) (4.0.0)\nRequirement already satisfied: pydantic<2 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[elasticsearch]) (1.10.14)\nRequirement already satisfied: quantulum3 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[elasticsearch]) (0.9.0)\nRequirement already satisfied: rank-bm25 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[elasticsearch]) (0.2.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from farm-haystack[elasticsearch]) (2.31.0)\nRequirement already satisfied: requests-cache<1.0.0 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[elasticsearch]) (0.9.8)\nRequirement already satisfied: scikit-learn>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[elasticsearch]) (1.4.1.post1)\nRequirement already satisfied: sseclient-py in /opt/conda/lib/python3.10/site-packages (from farm-haystack[elasticsearch]) (1.8.0)\nRequirement already satisfied: tenacity in /opt/conda/lib/python3.10/site-packages (from farm-haystack[elasticsearch]) (8.2.3)\nRequirement already satisfied: tiktoken>=0.5.1 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[elasticsearch]) (0.6.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from farm-haystack[elasticsearch]) (4.66.1)\nRequirement already satisfied: transformers==4.36.2 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[elasticsearch]) (4.36.2)\nRequirement already satisfied: pyyaml<7.0,>=6.0 in /opt/conda/lib/python3.10/site-packages (from prompthub-py==4.0.0->farm-haystack[elasticsearch]) (6.0.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2->farm-haystack[elasticsearch]) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2->farm-haystack[elasticsearch]) (0.20.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2->farm-haystack[elasticsearch]) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2->farm-haystack[elasticsearch]) (21.3)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2->farm-haystack[elasticsearch]) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2->farm-haystack[elasticsearch]) (0.15.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2->farm-haystack[elasticsearch]) (0.4.2)\nRequirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<2->farm-haystack[elasticsearch]) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->farm-haystack[elasticsearch]) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->farm-haystack[elasticsearch]) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->farm-haystack[elasticsearch]) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->farm-haystack[elasticsearch]) (2024.2.2)\nRequirement already satisfied: appdirs>=1.4.4 in /opt/conda/lib/python3.10/site-packages (from requests-cache<1.0.0->farm-haystack[elasticsearch]) (1.4.4)\nRequirement already satisfied: attrs>=21.2 in /opt/conda/lib/python3.10/site-packages (from requests-cache<1.0.0->farm-haystack[elasticsearch]) (23.2.0)\nRequirement already satisfied: cattrs>=22.2 in /opt/conda/lib/python3.10/site-packages (from requests-cache<1.0.0->farm-haystack[elasticsearch]) (23.2.3)\nRequirement already satisfied: url-normalize>=1.4 in /opt/conda/lib/python3.10/site-packages (from requests-cache<1.0.0->farm-haystack[elasticsearch]) (1.4.3)\nRequirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.3.0->farm-haystack[elasticsearch]) (1.11.4)\nRequirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.3.0->farm-haystack[elasticsearch]) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.3.0->farm-haystack[elasticsearch]) (3.2.0)\nCollecting elastic-transport<8 (from farm-haystack[elasticsearch])\n  Downloading elastic_transport-7.16.0-py2.py3-none-any.whl.metadata (8.1 kB)\nCollecting elasticsearch<8,>=7.17 (from farm-haystack[elasticsearch])\n  Downloading elasticsearch-7.17.9-py2.py3-none-any.whl.metadata (5.7 kB)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx->farm-haystack[elasticsearch]) (4.2.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx->farm-haystack[elasticsearch]) (1.0.4)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->farm-haystack[elasticsearch]) (1.3.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx->farm-haystack[elasticsearch]) (0.14.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->farm-haystack[elasticsearch]) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema->farm-haystack[elasticsearch]) (0.32.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->farm-haystack[elasticsearch]) (0.16.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->farm-haystack[elasticsearch]) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->farm-haystack[elasticsearch]) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->farm-haystack[elasticsearch]) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from posthog->farm-haystack[elasticsearch]) (1.16.0)\nRequirement already satisfied: monotonic>=1.5 in /opt/conda/lib/python3.10/site-packages (from posthog->farm-haystack[elasticsearch]) (1.6)\nRequirement already satisfied: backoff>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from posthog->farm-haystack[elasticsearch]) (2.2.1)\nRequirement already satisfied: inflect in /opt/conda/lib/python3.10/site-packages (from quantulum3->farm-haystack[elasticsearch]) (7.0.0)\nRequirement already satisfied: num2words in /opt/conda/lib/python3.10/site-packages (from quantulum3->farm-haystack[elasticsearch]) (0.5.13)\nRequirement already satisfied: exceptiongroup>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from cattrs>=22.2->requests-cache<1.0.0->farm-haystack[elasticsearch]) (1.2.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2->farm-haystack[elasticsearch]) (2024.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.36.2->farm-haystack[elasticsearch]) (3.1.1)\nRequirement already satisfied: docopt>=0.6.2 in /opt/conda/lib/python3.10/site-packages (from num2words->quantulum3->farm-haystack[elasticsearch]) (0.6.2)\nDownloading elastic_transport-7.16.0-py2.py3-none-any.whl (35 kB)\nDownloading elasticsearch-7.17.9-py2.py3-none-any.whl (385 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m386.0/386.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: elasticsearch, elastic-transport\nSuccessfully installed elastic-transport-7.16.0 elasticsearch-7.17.9\n","output_type":"stream"}]},{"cell_type":"code","source":"from haystack.document_stores import ElasticsearchDocumentStore\n# Return the document embedding for later use with dense retriever\ndocument_store = ElasticsearchDocumentStore(return_embedding=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T11:43:19.006839Z","iopub.execute_input":"2024-02-29T11:43:19.007576Z","iopub.status.idle":"2024-02-29T11:43:20.143474Z","shell.execute_reply.started":"2024-02-29T11:43:19.007539Z","shell.execute_reply":"2024-02-29T11:43:20.142303Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Unexpected exception formatting exception. Falling back to standard exception\n","output_type":"stream"},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_34/3623996901.py\", line 1, in <module>\n    from haystack.document_stores import ElasticsearchDocumentStore\n  File \"/opt/conda/lib/python3.10/site-packages/haystack/__init__.py\", line 10, in <module>\n    from haystack.schema import Document, Answer, Label, MultiLabel, Span, EvaluationResult, TableCell\n  File \"/opt/conda/lib/python3.10/site-packages/haystack/schema.py\", line 19, in <module>\n    from pydantic import BaseConfig, Field\n  File \"/opt/conda/lib/python3.10/site-packages/pydantic/__init__.py\", line 383, in __getattr__\n  File \"/opt/conda/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\nModuleNotFoundError: No module named 'pydantic.deprecated.config'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2144, in showtraceback\n    stb = self.InteractiveTB.structured_traceback(\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n    return FormattedTB.structured_traceback(\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n    return VerboseTB.structured_traceback(\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n    frames.append(self.format_record(record))\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n    frame_info.lines, Colors, self.has_colors, lvals\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 792, in lines\n    return self._sd.lines\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n    value = obj.__dict__[self.func.__name__] = self.func(obj)\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/core.py\", line 734, in lines\n    pieces = self.included_pieces\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n    value = obj.__dict__[self.func.__name__] = self.func(obj)\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/core.py\", line 681, in included_pieces\n    pos = scope_pieces.index(self.executing_piece)\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n    value = obj.__dict__[self.func.__name__] = self.func(obj)\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/core.py\", line 660, in executing_piece\n    return only(\n  File \"/opt/conda/lib/python3.10/site-packages/executing/executing.py\", line 116, in only\n    raise NotOneValueFound('Expected one value, found 0')\nexecuting.executing.NotOneValueFound: Expected one value, found 0\n","output_type":"stream"}]},{"cell_type":"code","source":"for split, df in dfs.items():\n\t# Exclude duplicate reviews\n\tdocs = [{\"text\": row[\"context\"], \"meta\":{\"item_id\": row[\"title\"], \"question_id\": row[\"id\"], \"split\": split}}\n\tfor _,row in df.drop_duplicates(subset=\"context\").iterrows()]\n\n\t# Extract the text content from each row\n\tfor doc in docs:\n\t\tdoc[\"content\"] = doc[\"text\"]\n\n\tdocument_store.write_documents(docs, index=\"document\")\nprint(f\"Loaded {document_store.get_document_count()} documents\")","metadata":{"execution":{"iopub.status.busy":"2024-02-29T11:43:23.514801Z","iopub.execute_input":"2024-02-29T11:43:23.515182Z","iopub.status.idle":"2024-02-29T11:43:23.656509Z","shell.execute_reply.started":"2024-02-29T11:43:23.515146Z","shell.execute_reply":"2024-02-29T11:43:23.655316Z"},"trusted":true},"execution_count":31,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[31], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \t\u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs:\n\u001b[1;32m      8\u001b[0m \t\tdoc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m doc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 10\u001b[0m \t\u001b[43mdocument_store\u001b[49m\u001b[38;5;241m.\u001b[39mwrite_documents(docs, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocument\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdocument_store\u001b[38;5;241m.\u001b[39mget_document_count()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m documents\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'document_store' is not defined"],"ename":"NameError","evalue":"name 'document_store' is not defined","output_type":"error"}]},{"cell_type":"code","source":"from haystack import ElasticsearchRetriever\nes_retriever = ElasticsearchRetriever(document_store=document_store)\nitem_id = \"B0074BW614\"\nquery = \"Is it good for reading?\"\nretrieved_docs = es_retriever.retrieve( query=query, top_k=3, filters={\"item_id\":[item_id], \"split\":[\"train\"]})\nprint(retrieved_docs[0])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from haystack.reader.farm import FARMReader\nmodel_ckpt = \"deepset/minilm-uncased-squad2\"\nmax_seq_length, doc_stride = 384, 128\nreader = FARMReader(model_name_or_path=model_ckpt, progress_bar=False, max_seq_len=max_seq_length, doc_stride=doc_stride, return_no_answer=True)\nprint(reader.predict_on_texts(question=question, texts=[context], top_k=1))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from haystack.pipeline import ExtractiveQAPipeline\npipe = ExtractiveQAPipeline(reader, es_retriever)\nn_answers = 3\npreds = pipe.run(query=query, top_k_retriever=3, top_k_reader=n_answers, filters={\"item_id\": [item_id], \"split\":[\"train\"]})\nprint(f\"Question: {preds['query']} \\n\")\nfor idx in range(n_answers):\n\tprint(f\"Answer {idx+1}: {preds['answers'][idx]['answer']}\")\n\tprint(f\"Review snippet: ...{preds['answers'][idx]['context']}...\")\n\tprint(\"\\n\\n\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from haystack.pipeline import Pipeline\nfrom haystack.eval import EvalDocuments\nclass EvalRetrieverPipeline:\n\tdef __init__(self, retriever):\n\t\tself.retriever = retriever\n\t\tself.eval_retriever = EvalDocuments()\n\t\tpipe = Pipeline() pipe.add_node(component=self.retriever, name=\"ESRetriever\", inputs=[\"Query\"])\n\t\tpipe.add_node(component=self.eval_retriever, name=\"EvalRetriever\", inputs=[\"ESRetriever\"])\n\t\tself.pipeline = pipe\n\npipe = EvalRetrieverPipeline(es_retriever)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}